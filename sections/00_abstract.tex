Computer Vision has traditional 

Existing video question answering benchmarks are limited in the spatio-temporal reasoning skills they measure, which limits our ability to measure models' abilities. We build a pipeline to combine Action Genome's spatio-temporal scene graph annotations with predefined templates to create a new benchmark AGQA. AGQA's question templates create questions that test a wide variety of spatio-temporal reasoning skills, including action sequencing, temporal localization, human-object interaction recognition, length, repetition, and compositional reasoning. Along with XX question-answer pairs, AGQA contributes a suite of metrics to measure models' accuracy at different reasoning challenges and ability to generalize from simple to more complex tasks. We test existing models on this new benchmark to measure their relative strengths and weaknesses. \mgm{add results?}

Using AGQA, we evaluate modern visual reasoning systems, providing novel insights into their abilities and limitations.