\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{anderson2016spice}
Peter Anderson, Basura Fernando, Mark Johnson, and Stephen Gould.
\newblock Spice: Semantic propositional image caption evaluation.
\newblock In {\em European Conference on Computer Vision}, pages 382--398.
  Springer, 2016.

\bibitem{antol2015vqa}
Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra,
  C Lawrence~Zitnick, and Devi Parikh.
\newblock Vqa: Visual question answering.
\newblock In {\em Proceedings of the IEEE international conference on computer
  vision}, pages 2425--2433, 2015.

\bibitem{ashual2019specifying}
Oron Ashual and Lior Wolf.
\newblock Specifying object attributes and relations in interactive scene
  generation.
\newblock In {\em Proceedings of the IEEE International Conference on Computer
  Vision}, pages 4561--4569, 2019.

\bibitem{cheng2015break}
Justin Cheng, Jaime Teevan, Shamsi~T Iqbal, and Michael~S Bernstein.
\newblock Break it down: A comparison of macro-and microtasks.
\newblock In {\em Proceedings of the 33rd Annual ACM Conference on Human
  Factors in Computing Systems}, pages 4061--4064, 2015.

\bibitem{fan2019heterogeneous}
Chenyou Fan, Xiaofan Zhang, Shu Zhang, Wensheng Wang, Chi Zhang, and Heng
  Huang.
\newblock Heterogeneous memory enhanced multimodal attention model for video
  question answering.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 1999--2007, 2019.

\bibitem{goyal2017making}
Yash Goyal, Tejas Khot, Douglas Summers-Stay, Dhruv Batra, and Devi Parikh.
\newblock Making the v in vqa matter: Elevating the role of image understanding
  in visual question answering.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 6904--6913, 2017.

\bibitem{hudson2019gqa}
Drew~A Hudson and Christopher~D Manning.
\newblock Gqa: A new dataset for real-world visual reasoning and compositional
  question answering.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 6700--6709, 2019.

\bibitem{jang2017tgif}
Yunseok Jang, Yale Song, Youngjae Yu, Youngjin Kim, and Gunhee Kim.
\newblock Tgif-qa: Toward spatio-temporal reasoning in visual question
  answering.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 2758--2766, 2017.

\bibitem{ji2020action}
Jingwei Ji, Ranjay Krishna, Li Fei-Fei, and Juan~Carlos Niebles.
\newblock Action genome: Actions as compositions of spatio-temporal scene
  graphs.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 10236--10247, 2020.

\bibitem{johnson2018image}
Justin Johnson, Agrim Gupta, and Li Fei-Fei.
\newblock Image generation from scene graphs.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 1219--1228, 2018.

\bibitem{johnson2017clevr}
Justin Johnson, Bharath Hariharan, Laurens van~der Maaten, Li Fei-Fei, C
  Lawrence~Zitnick, and Ross Girshick.
\newblock Clevr: A diagnostic dataset for compositional language and elementary
  visual reasoning.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 2901--2910, 2017.

\bibitem{johnson2017inferring}
Justin Johnson, Bharath Hariharan, Laurens Van Der~Maaten, Judy Hoffman, Li
  Fei-Fei, C Lawrence~Zitnick, and Ross Girshick.
\newblock Inferring and executing programs for visual reasoning.
\newblock In {\em Proceedings of the IEEE International Conference on Computer
  Vision}, pages 2989--2998, 2017.

\bibitem{johnson2015image}
Justin Johnson, Ranjay Krishna, Michael Stark, Li-Jia Li, David Shamma, Michael
  Bernstein, and Li Fei-Fei.
\newblock Image retrieval using scene graphs.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 3668--3678, 2015.

\bibitem{kim2020answering}
Dae~Hyun Kim, Enamul Hoque, and Maneesh Agrawala.
\newblock Answering questions about charts and generating visual explanations.
\newblock In {\em Proceedings of the 2020 CHI Conference on Human Factors in
  Computing Systems}, pages 1--13, 2020.

\bibitem{kim2017deepstory}
Kyung-Min Kim, Min-Oh Heo, Seong-Ho Choi, and Byoung-Tak Zhang.
\newblock Deepstory: Video story qa by deep embedded memory networks.
\newblock {\em arXiv preprint arXiv:1707.00836}, 2017.

\bibitem{krishna2018referring}
Ranjay Krishna, Ines Chami, Michael Bernstein, and Li Fei-Fei.
\newblock Referring relationships.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 6867--6876, 2018.

\bibitem{krishna2017visual}
Ranjay Krishna, Yuke Zhu, Oliver Groth, Justin Johnson, Kenji Hata, Joshua
  Kravitz, Stephanie Chen, Yannis Kalantidis, Li-Jia Li, David~A Shamma, et~al.
\newblock Visual genome: Connecting language and vision using crowdsourced
  dense image annotations.
\newblock {\em International journal of computer vision}, 123(1):32--73, 2017.

\bibitem{lake2018generalization}
Brenden Lake and Marco Baroni.
\newblock Generalization without systematicity: On the compositional skills of
  sequence-to-sequence recurrent networks.
\newblock In {\em International Conference on Machine Learning}, pages
  2873--2882, 2018.

\bibitem{le2020hierarchical}
Thao~Minh Le, Vuong Le, Svetha Venkatesh, and Truyen Tran.
\newblock Hierarchical conditional relation networks for video question
  answering.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 9972--9981, 2020.

\bibitem{lei2018tvqa}
Jie Lei, Licheng Yu, Mohit Bansal, and Tamara~L Berg.
\newblock Tvqa: Localized, compositional video question answering.
\newblock {\em arXiv preprint arXiv:1809.01696}, 2018.

\bibitem{li2019beyond}
Xiangpeng Li, Jingkuan Song, Lianli Gao, Xianglong Liu, Wenbing Huang, Xiangnan
  He, and Chuang Gan.
\newblock Beyond rnns: Positional self-attention with co-attention for video
  question answering.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~33, pages 8658--8665, 2019.

\bibitem{maharaj2017dataset}
Tegan Maharaj, Nicolas Ballas, Anna Rohrbach, Aaron Courville, and Christopher
  Pal.
\newblock A dataset and exploration of models for understanding video data
  through fill-in-the-blank question-answering.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 6884--6893, 2017.

\bibitem{schulz2016probing}
Eric Schulz, Josh Tenenbaum, David~K Duvenaud, Maarten Speekenbrink, and
  Samuel~J Gershman.
\newblock Probing the compositionality of intuitive functions.
\newblock In {\em Advances in neural information processing systems}, pages
  3729--3737, 2016.

\bibitem{sigurdsson2016hollywood}
Gunnar~A Sigurdsson, G{\"u}l Varol, Xiaolong Wang, Ali Farhadi, Ivan Laptev,
  and Abhinav Gupta.
\newblock Hollywood in homes: Crowdsourcing data collection for activity
  understanding.
\newblock In {\em European Conference on Computer Vision}, pages 510--526.
  Springer, 2016.

\bibitem{tani2014self}
Jun Tani.
\newblock Self-organization and compositionality in cognitive brains: A
  neurorobotics study.
\newblock {\em Proceedings of the IEEE}, 102(4):586--605, 2014.

\bibitem{tapaswi2016movieqa}
Makarand Tapaswi, Yukun Zhu, Rainer Stiefelhagen, Antonio Torralba, Raquel
  Urtasun, and Sanja Fidler.
\newblock Movieqa: Understanding stories in movies through question-answering.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 4631--4640, 2016.

\bibitem{xu2017video}
Dejing Xu, Zhou Zhao, Jun Xiao, Fei Wu, Hanwang Zhang, Xiangnan He, and Yueting
  Zhuang.
\newblock Video question answering via gradually refined attention over
  appearance and motion.
\newblock In {\em Proceedings of the 25th ACM international conference on
  Multimedia}, pages 1645--1653, 2017.

\bibitem{yu2019activitynet}
Zhou Yu, Dejing Xu, Jun Yu, Ting Yu, Zhou Zhao, Yueting Zhuang, and Dacheng
  Tao.
\newblock Activitynet-qa: A dataset for understanding complex web videos via
  question answering.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~33, pages 9127--9134, 2019.

\bibitem{zacks2001events}
J Zacks, B Tversky, and G Iyer.
\newblock Perceiving, remembering, and communicating structure in events.
\newblock {\em Journal of Experimental Psychology: General}, 130:201--213,
  2018.

\bibitem{zellers2019recognition}
Rowan Zellers, Yonatan Bisk, Ali Farhadi, and Yejin Choi.
\newblock From recognition to cognition: Visual commonsense reasoning.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 6720--6731, 2019.

\bibitem{zeng2016leveraging}
Kuo-Hao Zeng, Tseng-Hung Chen, Ching-Yao Chuang, Yuan-Hong Liao, Juan~Carlos
  Niebles, and Min Sun.
\newblock Leveraging video descriptions to learn video question answering.
\newblock {\em arXiv preprint arXiv:1611.04021}, 2016.

\bibitem{zhu2016visual7w}
Yuke Zhu, Oliver Groth, Michael Bernstein, and Li Fei-Fei.
\newblock Visual7w: Grounded question answering in images.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 4995--5004, 2016.

\end{thebibliography}
